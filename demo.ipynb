{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.train(data='dataset/data.yaml', epochs=30, imgsz=640)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = model.val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val(data='dataset/data.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECT WITH TEST IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Function to perform inference and display results\n",
    "def run_inference(model_path, image_filename, dataset_dir):\n",
    "    # Construct the full image path using the dataset directory and image filename\n",
    "    image_path = os.path.join(dataset_dir, image_filename)\n",
    "    \n",
    "    # Load the model with the trained weights\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Perform inference on the specified image\n",
    "    results = model(image_path, save=True)\n",
    "    \n",
    "    # Display results (if it's a list, access the first item)\n",
    "    results[0].show()\n",
    "\n",
    "# Specify the path to the trained weights\n",
    "model_path = 'best.pt'\n",
    "\n",
    "# Specify the image filename you want to run inference on\n",
    "image_filename = 'IMG_1131_000290_jpg.rf.806bd79d72734eb31740e90c72b0addc.jpg'\n",
    "\n",
    "# Specify the dataset directory\n",
    "dataset_dir = 'dataset/test/images'\n",
    "\n",
    "# Run inference with the specified model and image\n",
    "run_inference(model_path, image_filename, dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Specify the path to the image\n",
    "image_path = 'dataset/train/images/IMG_1128_000025_jpg.rf.112af7e57a332d65fae4bc2507f4e958.jpg'\n",
    "\n",
    "# Load the image using OpenCV\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if the image was loaded correctly\n",
    "if image is None:\n",
    "    print(f\"Error: Image at {image_path} could not be loaded. Please check the path.\")\n",
    "else:\n",
    "    # Convert BGR image to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECT WITH VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Function to perform inference on a video\n",
    "def detect_in_video(model_path, video_path, output_video_path):\n",
    "    # Load the model with the trained weights\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video at {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get the video frame width, height, and frames per second (fps)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Define the codec and create a VideoWriter object to save the output video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # or use 'MP4V' for .mp4\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        # Read each frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break  # End of video\n",
    "\n",
    "        # Perform inference on the current frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Display the results on the frame (bounding boxes and labels)\n",
    "        annotated_frame = results[0].plot()  # Get the frame with bounding boxes\n",
    "        \n",
    "        # Write the frame to the output video file\n",
    "        out.write(annotated_frame)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Video Detection', annotated_frame)\n",
    "\n",
    "        # Press 'q' to quit the video window early\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release the video objects and close windows\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Specify the path to the trained model\n",
    "model_path = 'best.pt'\n",
    "\n",
    "# Specify the input video file\n",
    "video_path = 'slow-video.mp4'\n",
    "\n",
    "# Specify the output video file (where you want to save the annotated video)\n",
    "output_video_path = 'output_video.avi'\n",
    "\n",
    "# Run the detection on the video\n",
    "detect_in_video(model_path, video_path, output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo8-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
